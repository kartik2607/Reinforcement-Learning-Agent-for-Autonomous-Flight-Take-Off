{"agent": "ppo", "states": {"type": "float", "shape": [4]}, "actions": {"thrust": {"type": "int", "num_values": 6}, "theta": {"type": "int", "num_values": 15}}, "max_episode_timesteps": 1000, "network": {"type": "auto", "size": 32, "depth": 4}, "batch_size": 10, "update_frequency": 20, "learning_rate": 0.001, "likelihood_ratio_clipping": 0.1, "discount": 1.0, "estimate_terminal": false, "critic_network": "auto", "critic_optimizer": {"optimizer": "adam", "multi_step": 30, "learning_rate": 0.001}, "preprocessing": null, "exploration": 0.01, "variable_noise": 0.0, "l2_regularization": 0.1, "entropy_regularization": 0.01, "name": "agent_1", "device": null, "parallel_interactions": 5, "seed": 124, "execution": null, "saver": {"directory": "C:\\Users\\HAL\\Downloads\\PlaneModel (1)-20231211T035404Z-001\\PlaneModel\\Plane-Env\\env\\Models\\1", "filename": "agent_1"}, "summarizer": null, "recorder": {"directory": "C:\\Users\\HAL\\Downloads\\PlaneModel (1)-20231211T035404Z-001\\PlaneModel\\Plane-Env\\env\\Models\\1", "frequency": 1000}, "config": null}